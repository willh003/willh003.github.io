<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-E00L9PT3V9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-E00L9PT3V9');
  </script>
  <title>William Huey</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="William Huey" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                William Huey
              </h1>
              <p>Hi, I'm Will. I'm a Senior at Cornell University studying Computer Science, and I'm currently working with <a href="https://sanjibanc.github.io/">Prof. Sanjiban Choudhury</a> and the <a href="https://portal.cs.cornell.edu/">PoRTAL Lab</a> on learning robotic control from video demonstrations.
              </p>
              <p>
                In the past, I worked under Prof. Marco Hutter at the <a href="https://rsl.ethz.ch/">ETH Zurich Robotic Systems Lab</a> and <a href="https://aap.cornell.edu/people/donald-greenberg">Prof. Don Greenberg</a> at the <a href="https://www.graphics.cornell.edu/academics">Cornell Program of Computer Graphics</a>. I spent a summer as an intern at NASA and another at Amazon Web Services. At Cornell, I've maintained a 4.1 GPA, I was a teaching assistant for <a href="https://classes.cornell.edu/browse/roster/FA20/class/ART/2907">CS 1620: Visual Imaging in the Electronic Age</a>, and I'm a <a href="https://scl.cornell.edu/get-involved/cornell-commitment/rawlings-cornell-presidential-research-scholars">Rawlings Presidential Research Scholar</a>. 
              </p>
              <p style="color: #196f3d;">
                <b>I am applying to PhD programs for the fall 2025 admissions cycle. </b>
              </p>
              <p>
                Outside of school, I enjoy running marathons, climbing walls, and playing foot volley. Here are a few of my recent projects :)
              </p>
              <p style="text-align:center">
                <a target="_blank" href="https://mailhide.io/e/c0aYYbjk"> Email</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://github.com/willh003">GitHub</a> &nbsp;/&nbsp;
                <a target="_blank" href="https://www.linkedin.com/in/willhuey9"> LinkedIn </a> &nbsp;/&nbsp;
                <a target="_blank" href="https://willh003.github.io/files/cv.pdf"> CV </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/me.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in representation learning, reinforcement learning, and agentic decision making.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/sdtw_plus.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Time Your Rewards: Learning Temporally Consistent Rewards from a Single Video Demonstration</h3>
              <br>
              Huaxiaoyue Wang*, <strong>William Huey*</strong>, Anne Wu, Yoav Artzi, Sanjiban Choudhury

              <br>
              <em>CoRL 2024 Workshop on Whole-body Control and Bimanual Manipulation</em>, 2024
              <br>
              
              
              <a href="https://openreview.net/forum?id=gsgkiuv9BS">paper</a> /
              
              
              
              
              
              
              
              <a href="https://github.com/portal-cornell/CrossQ/tree/dev/refactor">code</a> /
              
              <p></p>
              <p>We show that existing approaches for inferring reward functions from video demonstrations result in temporal inconsistencies: agents complete subtasks in the wrong order, get stuck along the expert trajectory, or fail to stay in the final state. Our approach mitigates this problem, solving humanoid control tasks quickly and efficiently.</p>

            </td>
          </tr>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p> These include coursework, side projects and unpublished research work. 
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/anymal_site.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Distilling Vision-Language Models for Real-Time Traversability Prediction</h3>
            <br>
            <strong>William Huey*</strong>, Sean Brynjolfsson*, Donald Greenberg

            <br>
            <em>Cornell Discover Undergraduate Research in Engineering Showcase</em>, 2024
            <br>
              
              
              <a href="https://willh003.github.io/files/vtrav.pdf">paper</a> /
              
              
              
              
              
              
              
              <a href="https://willh003.github.io/files/dureposter.pdf">poster</a> /
              
              
              
              <a href="https://github.com/willh003/ovt">code</a> /
              
              <p></p>
              <p>Currently, most traversability prediction methods rely on heuristics, human demonstration, or pretraining on a specific set of object classes. We show that large pretrained vision language models can accurately predict traversability. Applying this insight, we distill fast traversability prediction models that run in real time on robot hardware, allowing for long horizon unguided exploration.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/superedge.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>SuperEdge: A CNN-Based Approach for Quadruped Traversability Analysis from Incomplete Observations</h3>
            <br>
            <strong>William Huey*</strong>

            <br>
            <em>CS 4756: Robot Learning Final Project</em>, 2023
            <br>
              
              
              <a href="https://willh003.github.io/files/superedge.pdf">paper</a> /
              
              
              
              
              
              <a href="https://www.youtube.com/watch?v=5CyWaL-u3ro&feature=youtu.be">video</a> /
              
              
              
              
              
              <a href="https://github.com/willh003/isaac-anymal-runner">code</a> /
              
              <p></p>
              <p>I demonstrate self-supervised traversability learning in simulation given sparse point cloud observations. To support this project, I developed a navigation stack for legged robots in Nvidia Isaac Sim, which includes traversability estimation, environment graph generation, graph search, and path tracking.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/ctfsm.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
            <h3>Practices in Combinatorial Testing Relevant to Spacecraft Software Verification</h3>
            <br>
            <strong>William Huey*</strong>, D. Richard Kuhn, William Stanton

            <br>
            <em>NASA Summer Intern Symposium</em>, 2022
            <br>
              
              
              
              
              
              
              
              
              
              
              <p></p>
              <p>Traditional code coverage metrics, like branch and line coverage, can miss dangerous combinations of inputs to a program. Combinatorial testing is a method for covering the input space of a program, but it had not previously been investigated in the context of state-machine based systems, such as those used for flight control software. I developed a tool that automatically generates tests for these systems with a specified degree of combinatorial coverage.</p>

            </td>
          </tr>
          
          
          
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from
                <a style="font-size:small;" href="https://leonidk.com/">Leonid Keselman's</a> Jekyll fork of
                <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's</a> website
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

