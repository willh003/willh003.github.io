<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-22T15:55:54-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">William Huey</title><entry><title type="html">Time Your Rewards: Learning Temporally Consistent Rewards from a Single Video Demonstration</title><link href="http://localhost:4000/" rel="alternate" type="text/html" title="Time Your Rewards: Learning Temporally Consistent Rewards from a Single Video Demonstration" /><published>2024-10-30T18:21:59-04:00</published><updated>2024-10-30T18:21:59-04:00</updated><id>http://localhost:4000/tyr</id><content type="html" xml:base="http://localhost:4000/"><![CDATA[<p>We show that existing approaches for inferring reward functions from video demonstrations result in temporal inconsistencies: agents complete subtasks in the wrong order, get stuck along the expert trajectory, or fail to stay in the final state. Our approach mitigates this problem, solving humanoid control tasks quickly and efficiently.</p>]]></content><author><name>Will Huey</name></author><category term="research" /><summary type="html"><![CDATA[We show that existing approaches for inferring reward functions from video demonstrations result in temporal inconsistencies: agents complete subtasks in the wrong order, get stuck along the expert trajectory, or fail to stay in the final state. Our approach mitigates this problem, solving humanoid control tasks quickly and efficiently.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/sdtw_plus.png" /><media:content medium="image" url="http://localhost:4000/images/sdtw_plus.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Distilling Vision-Language Models for Real-Time Traversability Prediction</title><link href="http://localhost:4000/" rel="alternate" type="text/html" title="Distilling Vision-Language Models for Real-Time Traversability Prediction" /><published>2024-10-12T18:21:59-04:00</published><updated>2024-10-12T18:21:59-04:00</updated><id>http://localhost:4000/vtrav</id><content type="html" xml:base="http://localhost:4000/"><![CDATA[<p>Currently, most traversability prediction methods rely on heuristics, human demonstration, or pretraining on a specific set of object classes. We show that large pretrained vision language models can accurately predict traversability. Applying this insight, we distill fast traversability prediction models that run in real time on robot hardware, allowing for long horizon unguided exploration.</p>]]></content><author><name>Will Huey</name></author><category term="other" /><summary type="html"><![CDATA[Currently, most traversability prediction methods rely on heuristics, human demonstration, or pretraining on a specific set of object classes. We show that large pretrained vision language models can accurately predict traversability. Applying this insight, we distill fast traversability prediction models that run in real time on robot hardware, allowing for long horizon unguided exploration.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/anymal_site.gif" /><media:content medium="image" url="http://localhost:4000/images/anymal_site.gif" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Practices in Combinatorial Testing Relevant to Spacecraft Software Verification</title><link href="http://localhost:4000/" rel="alternate" type="text/html" title="Practices in Combinatorial Testing Relevant to Spacecraft Software Verification" /><published>2023-05-24T18:21:59-04:00</published><updated>2023-05-24T18:21:59-04:00</updated><id>http://localhost:4000/ctfsm</id><content type="html" xml:base="http://localhost:4000/"><![CDATA[<p>Traditional code coverage metrics, like branch and line coverage, can miss dangerous combinations of inputs to a program. Combinatorial testing is a method for covering the input space of a program, but it had not previously been investigated in the context of state-machine based systems, such as those used for flight control software. I developed a tool that automatically generates tests for these systems with a specified degree of combinatorial coverage.</p>]]></content><author><name>Will Huey</name></author><category term="other" /><summary type="html"><![CDATA[Traditional code coverage metrics, like branch and line coverage, can miss dangerous combinations of inputs to a program. Combinatorial testing is a method for covering the input space of a program, but it had not previously been investigated in the context of state-machine based systems, such as those used for flight control software. I developed a tool that automatically generates tests for these systems with a specified degree of combinatorial coverage.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/ctfsm.png" /><media:content medium="image" url="http://localhost:4000/images/ctfsm.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">SuperEdge: A CNN-Based Approach for Quadruped Traversability Analysis from Incomplete Observations</title><link href="http://localhost:4000/" rel="alternate" type="text/html" title="SuperEdge: A CNN-Based Approach for Quadruped Traversability Analysis from Incomplete Observations" /><published>2023-05-24T18:21:59-04:00</published><updated>2023-05-24T18:21:59-04:00</updated><id>http://localhost:4000/superedge</id><content type="html" xml:base="http://localhost:4000/"><![CDATA[<p>I demonstrate self-supervised traversability learning in simulation given sparse point cloud observations. To support this project, I developed a navigation stack for legged robots in Nvidia Isaac Sim, which includes traversability estimation, environment graph generation, graph search, and path tracking.</p>]]></content><author><name>Will Huey</name></author><category term="other" /><summary type="html"><![CDATA[I demonstrate self-supervised traversability learning in simulation given sparse point cloud observations. To support this project, I developed a navigation stack for legged robots in Nvidia Isaac Sim, which includes traversability estimation, environment graph generation, graph search, and path tracking.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/superedge.png" /><media:content medium="image" url="http://localhost:4000/images/superedge.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>